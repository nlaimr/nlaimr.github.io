---
title: 'Analyzing Large Language Model Internals'
date: 2012-08-14
permalink: /posts/2012/08/blog-post-1/
tags:
  - neuron-level-analysis
  - neuron-function
---

Paper: Neurons in Large Language Models: Dead, N-gram, Positional
======

Abstract: Key findings
----
- Early part of the network is sparse and represents many discrete features.
- Layers are sparsely activated with many of the alive neurons being reserved for discrete features and act as token and n-gram detectors
- Some neurons are positional: them being activated or not depends largely (or solely) on position and less so (or not at all) on textual data. We find that smaller models have sets of neurons acting as position range indicators while larger models operate in a less explicit manner.

Supporting evidence for the claims
-----

High level implementation details:
-----
- focus on neurons inside FFNs: FFN neurons are more likely to represent meaningful features: the elementwise nonlinearity breaks the rotational invariance of this representation and encourages features to align with the basis dimensions
- 
